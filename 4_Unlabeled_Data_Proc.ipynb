{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744db98e-f816-418b-a3bb-d7f7cc5ed8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn import model_selection\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.symbols import ORTH\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import random\n",
    "import sys \n",
    "import math\n",
    "import os\n",
    "sys.path.append('./luima_sbd')\n",
    "import luima_sbd.sbd_utils as luima\n",
    "from spacy.language import Language\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecefc8b-c4a9-4b95-8601-272f756f6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7c890-21a8-4be8-a935-9a59358d7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_fpath = './ldsi_s2021/ldsi_bva_sentence_corpus_v1.json'\n",
    "data = json.load(open(corpus_fpath))\n",
    "affirmed = open('./ldsi_s2021/affirmed_ids.txt', 'r').read().split(\"\\n\")\n",
    "denied= open('./ldsi_s2021/denied_ids.txt', 'r').read().split(\"\\n\")\n",
    "remanded = open('./ldsi_s2021/remanded_ids.txt', 'r').read().split(\"\\n\")\n",
    "# print(len(affirmed), len(denied), len(remanded))\n",
    "annotations = data['annotations']\n",
    "documents_by_id = {d['_id']: d for d in data['documents']}\n",
    "types_by_id = {t['_id']: t for t in data['types']}\n",
    "type_ids_by_name = {t['name']: t['_id'] for t in data['types']}\n",
    "type_names_by_id = {t['_id']: t['name'] for t in data['types']}\n",
    "doc_id_by_name = {d['name']: d['_id'] for d in data['documents']}\n",
    "doc_name_by_id = {d['_id']: d['name'] for d in data['documents']}\n",
    "\n",
    "def make_span_data(documents_by_id, types_by_id, annotations):\n",
    "    span_data = []\n",
    "    for a in annotations:\n",
    "        start = a['start']\n",
    "        end = a['end']\n",
    "        document_txt = documents_by_id[a['document']]['plainText']\n",
    "        atype = a['type']\n",
    "        document_name=documents_by_id[a['document']]['name']\n",
    "        if document_name in affirmed:\n",
    "            decision='affirmed'\n",
    "        elif document_name in denied:\n",
    "            decision='denied'\n",
    "        elif document_name in remanded:\n",
    "            decision='remanded'\n",
    "        sd = {'txt': document_txt[start:end],\n",
    "              'document': a['document'],\n",
    "              'type': types_by_id[atype]['name'],\n",
    "              'start': a['start'],\n",
    "              'start_normalized': a['start'] / len(document_txt),\n",
    "              'end': a['end'],\n",
    "              'name': document_name,\n",
    "              'decisions': decision}\n",
    "        span_data.append(sd)\n",
    "    return span_data\n",
    "\n",
    "spans = make_span_data(documents_by_id, types_by_id, annotations)\n",
    "span_labels = [s['type'] for s in spans]\n",
    "span_decisions = [s['decisions'] for s in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5a26b-496f-4611-b5f0-7d0708afc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "aff=random.sample(affirmed, 6)\n",
    "den=random.sample(denied, 6)\n",
    "rem=random.sample(remanded, 6)\n",
    "test_affirm, dev_affirm = aff[0:3], aff[3:6] \n",
    "test_denied, dev_denied = den[0:3], den[3:6] \n",
    "test_remanded, dev_remanded = rem[0:3], rem[3:6] \n",
    "\n",
    "test_ids = test_affirm+test_denied+test_remanded\n",
    "dev_ids = dev_affirm+dev_denied+dev_remanded\n",
    "\n",
    "test_spans=[]\n",
    "dev_spans=[]\n",
    "train_spans=[]\n",
    "for s in spans:\n",
    "    if s['name'] in test_ids:\n",
    "        test_spans.append(s)\n",
    "    elif s['name'] in dev_ids:\n",
    "        dev_spans.append(s)\n",
    "    else:\n",
    "        train_spans.append(s)\n",
    "        \n",
    "unique_files=pd.DataFrame(train_spans).name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff26630-32f0-4c0f-9f2d-c1a7c1f17482",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=os.listdir(\"./ldsi_s2021/unlabeled/unlabeled/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921cd6d-84ad-4710-9be9-8ccff7e748ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_tp=0\n",
    "tot_fp=0\n",
    "tot_fn=0\n",
    "result = []\n",
    "\n",
    "# [{'File': '0843259.txt',\n",
    "#   'Precision': 0.2916666666666667,\n",
    "#   'Recall': 0.5185185185185185,\n",
    "#   'F1_Score': 0.37333333333333335},\n",
    "#  {'File': '0942105.txt',\n",
    "#   'Precision': 0.3767123287671233,\n",
    "#   'Recall': 0.6043956043956044,\n",
    "#   'F1_Score': 0.46413502109704635},\n",
    "#  {'File': '0820506.txt',\n",
    "#   'Precision': 0.40540540540540543,\n",
    "#   'Recall': 0.6521739130434783,\n",
    "#   'F1_Score': 0.5}]\n",
    "\n",
    "result_dict=[]\n",
    "for file in file_list:\n",
    "#     print(file)\n",
    "    doc = open(f'./ldsi_s2021/unlabeled/unlabeled/{file}', 'r').read()\n",
    "\n",
    "    sentences = luima.text2sentences(doc, offsets=False)\n",
    "    index = luima.text2sentences(doc, offsets=True)\n",
    "    count_dict={\n",
    "        \"file_name\":file,\n",
    "        \"sent_count\":len(sentences),\n",
    "        \"sentences\":sentences\n",
    "    }\n",
    "    result_dict.append(count_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b8cd3-34f2-4165-bf95-ca19a4961ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9ecd6-42fd-4dc3-ac7c-d95f1fca3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(\"./sentence_segmented_dict.pkl\")\n",
    "df = pd.read_pickle(\"./sentence_segmented_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e4554-dcba-4db1-889f-d2da962e4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df.sent_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc27340-6aa5-4df0-9d2a-9425a5963c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d293b-2c8e-4705-a80f-15a00306428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width= 0.5\n",
    "# here you can choose your rounding method, I've chosen math.ceil\n",
    "nbins = math.ceil((df[\"sent_count\"].max() - df[\"sent_count\"].min()) / bin_width)\n",
    "print(nbins)\n",
    "fig = px.histogram(df, x=\"sent_count\", nbins=nbins,\n",
    "            width=1200, height=600,\n",
    "            labels={ # replaces default labels by column name\n",
    "                \"sent_count\": \"Number of Sentences\",\n",
    "            },\n",
    "            template=\"plotly_white\")\n",
    "fig.update_yaxes(showgrid=True)\n",
    "fig.update_layout(title_text=\"Histogram of Number of Sentences in Each Document\", title_x=0.5, font_size=18)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696793a-a51a-4398-a47f-029a1fb309ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
