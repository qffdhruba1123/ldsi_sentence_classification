{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aab8f0-2baa-4924-89f9-fa7847e7392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn import model_selection\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.symbols import ORTH\n",
    "from spacy.symbols import NORM\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import plotly.express as px\n",
    "import sys \n",
    "import fasttext\n",
    "sys.path.append('./luima_sbd')\n",
    "import luima_sbd.sbd_utils as luima\n",
    "from spacy.language import Language\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7626e-ba79-466a-8dfd-4f1de889c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35030e90-f4f0-40bd-8d91-bf30fb63cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_tfidf_features(row, features, top_n=15):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "\n",
    "def top_features_in_doc(Xtr, features, row_id, top_n=15):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    xtr_row = Xtr[row_id]\n",
    "    if type(xtr_row) is not np.ndarray:\n",
    "        xtr_row = xtr_row.toarray()\n",
    "    row = np.squeeze(xtr_row)\n",
    "    return top_tfidf_features(row, features, top_n)\n",
    "\n",
    "\n",
    "def top_mean_features(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids]\n",
    "    else:\n",
    "        D = Xtr\n",
    "    if type(D) is not np.ndarray:\n",
    "        D = D.toarray()\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_features(tfidf_means, features, top_n)\n",
    "\n",
    "\n",
    "def top_features_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = {}\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_features(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs[label] = feats_df\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def span_top_tfidf(spans_txt, spans_tfidf, features, index):\n",
    "    print('span text:\\n'+spans_txt[index]+'\\n')\n",
    "    print(top_features_in_doc(spans_tfidf, features, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527163af-3371-4e45-aed5-a49603932eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_fpath = './ldsi_s2021/ldsi_bva_sentence_corpus_v1.json'\n",
    "data = json.load(open(corpus_fpath))\n",
    "affirmed = open('./ldsi_s2021/affirmed_ids.txt', 'r').read().split(\"\\n\")\n",
    "denied= open('./ldsi_s2021/denied_ids.txt', 'r').read().split(\"\\n\")\n",
    "remanded = open('./ldsi_s2021/remanded_ids.txt', 'r').read().split(\"\\n\")\n",
    "# print(len(affirmed), len(denied), len(remanded))\n",
    "annotations = data['annotations']\n",
    "documents_by_id = {d['_id']: d for d in data['documents']}\n",
    "types_by_id = {t['_id']: t for t in data['types']}\n",
    "type_ids_by_name = {t['name']: t['_id'] for t in data['types']}\n",
    "type_names_by_id = {t['_id']: t['name'] for t in data['types']}\n",
    "doc_id_by_name = {d['name']: d['_id'] for d in data['documents']}\n",
    "doc_name_by_id = {d['_id']: d['name'] for d in data['documents']}\n",
    "\n",
    "def make_span_data(documents_by_id, types_by_id, annotations):\n",
    "    span_data = []\n",
    "    for a in annotations:\n",
    "        start = a['start']\n",
    "        end = a['end']\n",
    "        document_txt = documents_by_id[a['document']]['plainText']\n",
    "        atype = a['type']\n",
    "        document_name=documents_by_id[a['document']]['name']\n",
    "        if document_name in affirmed:\n",
    "            decision='affirmed'\n",
    "        elif document_name in denied:\n",
    "            decision='denied'\n",
    "        elif document_name in remanded:\n",
    "            decision='remanded'\n",
    "        sd = {'txt': document_txt[start:end],\n",
    "              'document': a['document'],\n",
    "              'type': types_by_id[atype]['name'],\n",
    "              'start': a['start'],\n",
    "              'start_normalized': a['start'] / len(document_txt),\n",
    "              'end': a['end'],\n",
    "              'name': document_name,\n",
    "              'decisions': decision}\n",
    "        span_data.append(sd)\n",
    "    return span_data\n",
    "\n",
    "spans = make_span_data(documents_by_id, types_by_id, annotations)\n",
    "span_labels = [s['type'] for s in spans]\n",
    "span_decisions = [s['decisions'] for s in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68946e16-ca32-454e-9da5-f6f62d764bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "aff=random.sample(affirmed, 6)\n",
    "den=random.sample(denied, 6)\n",
    "rem=random.sample(remanded, 6)\n",
    "test_affirm, dev_affirm = aff[0:3], aff[3:6] \n",
    "test_denied, dev_denied = den[0:3], den[3:6] \n",
    "test_remanded, dev_remanded = rem[0:3], rem[3:6] \n",
    "\n",
    "test_ids = test_affirm+test_denied+test_remanded\n",
    "dev_ids = dev_affirm+dev_denied+dev_remanded\n",
    "\n",
    "test_spans=[]\n",
    "dev_spans=[]\n",
    "train_spans=[]\n",
    "for s in spans:\n",
    "    if s['name'] in test_ids:\n",
    "        test_spans.append(s)\n",
    "    elif s['name'] in dev_ids:\n",
    "        dev_spans.append(s)\n",
    "    else:\n",
    "        train_spans.append(s)\n",
    "        \n",
    "unique_files=pd.DataFrame(train_spans).name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a79ee0-5c02-4aea-b0a8-39d96ae604cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = pd.read_pickle(\"./token_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b28b58-fedd-41c8-99f7-4f95bddce15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model = fasttext.train_unsupervised('./fastTextFinalShuffled.txt', epoch=10, minCount=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb4328-e17b-4224-8809-794bfdd00d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"result/wordEmbeddingsModel.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba87f5-99cc-42f1-8dd2-13822005c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(\"result/wordEmbeddingsModel.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd81e45-be49-4682-85bf-ea037c405cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_words(on_unicode_error='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbae76-06b5-4e85-8a3c-955003d8bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words=[\"veteran\",\"vet\",\"service\",\"cause\",\"caused\",\"remanded\",\"vietnam\",\"see\",\"board\",\"notice\",\"claim\", \"judge\",\"records\",\"letter\"]\n",
    "test_word_track=[]\n",
    "for word in test_words:\n",
    "    nearest_neigh=model.get_nearest_neighbors(word)\n",
    "    app_dict={\n",
    "        \"test_word\": word,\n",
    "        \"nearest_neighbours\": nearest_neigh\n",
    "    }\n",
    "    test_word_track.append(app_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225286b-e72d-4093-a8bd-8d10ad220f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_word_track)\n",
    "df.to_pickle(\"./word_emd_NN.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcab504-d4a3-46b4-b2c9-886a46d71c58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_word_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019a384-92d2-426d-ad2f-793f447035ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
